#!/usr/bin/env python3
"""
YOLOv10 ä»ªè¡¨æ£€æµ‹æ¨¡å‹è®­ç»ƒè„šæœ¬

æ­¤è„šæœ¬ç”¨äºè®­ç»ƒYOLOv10æ¨¡å‹æ¥æ£€æµ‹å·¥ä¸šä»ªè¡¨ã€‚
æ”¯æŒä»COCOæ ¼å¼æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼ŒåŒ…å«æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€éªŒè¯ç­‰åŠŸèƒ½ã€‚

ä½œè€…: chijiang
æ—¥æœŸ: 2025-06-06
"""

import os
import sys
import argparse
import yaml
import json
import shutil
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import torch
import cv2
import numpy as np
from ultralytics import YOLO
from ultralytics.utils import LOGGER
from ultralytics.utils.plotting import Annotator, colors
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings

warnings.filterwarnings('ignore')

class MeterDetectionTrainer:
    """ä»ªè¡¨æ£€æµ‹è®­ç»ƒå™¨"""
    
    def __init__(self, config_path: str):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self.load_config(config_path)
        self.project_root = Path(__file__).parent.parent
        self.setup_directories()
        
    def load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        return config
    
    def _get_device(self) -> str:
        """
        æ™ºèƒ½æ£€æµ‹æœ€ä½³è®¾å¤‡
        
        Returns:
            è®¾å¤‡å­—ç¬¦ä¸²
        """
        config_device = self.config.get('device', 'auto')
        
        if config_device != 'auto':
            return config_device
        
        # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
        if torch.cuda.is_available():
            device = '0'
            print(f"ğŸ”¥ Using CUDA GPU: {torch.cuda.get_device_name(0)}")
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            device = 'mps'
            print("ğŸ Using Apple MPS acceleration")
        else:
            device = 'cpu'
            print("ğŸ’» Using CPU")
        
        # è¾“å‡ºè®¾å¤‡ä¿¡æ¯
        print(f"ğŸ¯ Device selected: {device}")
        if device == 'mps':
            print("â„¹ï¸  Apple Silicon detected - using Metal Performance Shaders for acceleration")
        elif device == 'cpu':
            print("âš ï¸  No GPU acceleration available - training will be slower")
            
        return device
    
    def setup_directories(self):
        """è®¾ç½®è¾“å‡ºç›®å½•"""
        self.output_dir = self.project_root / "outputs"
        self.checkpoint_dir = self.output_dir / "checkpoints" / "detection"
        self.log_dir = self.output_dir / "logs" / "detection"
        self.result_dir = self.output_dir / "results" / "detection"
        
        # åˆ›å»ºç›®å½•
        for dir_path in [self.checkpoint_dir, self.log_dir, self.result_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
    
    def prepare_yolo_dataset(self) -> str:
        """
        å°†COCOæ ¼å¼æ•°æ®è½¬æ¢ä¸ºYOLOæ ¼å¼
        
        Returns:
            YOLOæ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
        """
        print("ğŸ”„ Converting COCO dataset to YOLO format...")
        
        # æ•°æ®è·¯å¾„
        data_root = self.project_root / "data" / "detection"
        yolo_root = self.project_root / "data" / "detection_yolo"
        
        # åˆ›å»ºYOLOæ ¼å¼ç›®å½•
        yolo_root.mkdir(exist_ok=True)
        (yolo_root / "images" / "train").mkdir(parents=True, exist_ok=True)
        (yolo_root / "images" / "val").mkdir(parents=True, exist_ok=True)
        (yolo_root / "labels" / "train").mkdir(parents=True, exist_ok=True)
        (yolo_root / "labels" / "val").mkdir(parents=True, exist_ok=True)
        
        # è½¬æ¢è®­ç»ƒé›†å’ŒéªŒè¯é›†
        for split in ['train', 'val']:
            self._convert_coco_to_yolo(
                coco_ann_file=data_root / "annotations" / f"meter_coco_{split}.json",
                image_dir=data_root / f"{split}2017",
                output_image_dir=yolo_root / "images" / split,
                output_label_dir=yolo_root / "labels" / split
            )
        
        # åˆ›å»ºæ•°æ®é›†é…ç½®æ–‡ä»¶
        dataset_config = {
            'train': str(yolo_root / "images" / "train"),
            'val': str(yolo_root / "images" / "val"),
            'nc': 1,  # ç±»åˆ«æ•°é‡
            'names': ['meter']  # ç±»åˆ«åç§°
        }
        
        config_path = yolo_root / "dataset.yaml"
        with open(config_path, 'w') as f:
            yaml.dump(dataset_config, f)
        
        return str(config_path)
    
    def _convert_coco_to_yolo(self, coco_ann_file: Path, image_dir: Path, 
                             output_image_dir: Path, output_label_dir: Path):
        """è½¬æ¢å•ä¸ªCOCOæ•°æ®é›†åˆ°YOLOæ ¼å¼"""
        
        # åŠ è½½COCOæ ‡æ³¨
        with open(coco_ann_file, 'r') as f:
            coco_data = json.load(f)
        
        # æ„å»ºå›¾åƒIDåˆ°æ–‡ä»¶åçš„æ˜ å°„
        image_id_to_filename = {img['id']: img['file_name'] for img in coco_data['images']}
        image_id_to_size = {img['id']: (img['width'], img['height']) for img in coco_data['images']}
        
        # æŒ‰å›¾åƒIDåˆ†ç»„æ ‡æ³¨
        annotations_by_image = {}
        for ann in coco_data['annotations']:
            image_id = ann['image_id']
            if image_id not in annotations_by_image:
                annotations_by_image[image_id] = []
            annotations_by_image[image_id].append(ann)
        
        # è½¬æ¢æ¯ä¸ªå›¾åƒ
        for image_id, filename in tqdm(image_id_to_filename.items(), desc=f"Converting {coco_ann_file.stem}"):
            # å¤åˆ¶å›¾åƒæ–‡ä»¶
            src_image_path = image_dir / filename
            dst_image_path = output_image_dir / filename
            
            if src_image_path.exists():
                if not dst_image_path.exists():
                    shutil.copy2(src_image_path, dst_image_path)
                
                # è½¬æ¢æ ‡æ³¨
                if image_id in annotations_by_image:
                    width, height = image_id_to_size[image_id]
                    yolo_labels = []
                    
                    for ann in annotations_by_image[image_id]:
                        bbox = ann['bbox']  # [x, y, width, height]
                        
                        # è½¬æ¢ä¸ºYOLOæ ¼å¼ [class_id, x_center, y_center, width, height] (ç›¸å¯¹åæ ‡)
                        x_center = (bbox[0] + bbox[2] / 2) / width
                        y_center = (bbox[1] + bbox[3] / 2) / height
                        norm_width = bbox[2] / width
                        norm_height = bbox[3] / height
                        
                        # COCOç±»åˆ«IDä»1å¼€å§‹ï¼ŒYOLOä»0å¼€å§‹
                        class_id = ann['category_id'] - 1
                        
                        yolo_labels.append(f"{class_id} {x_center:.6f} {y_center:.6f} {norm_width:.6f} {norm_height:.6f}")
                    
                    # ä¿å­˜YOLOæ ‡æ³¨æ–‡ä»¶
                    label_filename = filename.rsplit('.', 1)[0] + '.txt'
                    label_path = output_label_dir / label_filename
                    with open(label_path, 'w') as f:
                        f.write('\n'.join(yolo_labels))
                else:
                    # åˆ›å»ºç©ºæ ‡æ³¨æ–‡ä»¶ï¼ˆè´Ÿæ ·æœ¬ï¼‰
                    label_filename = filename.rsplit('.', 1)[0] + '.txt'
                    label_path = output_label_dir / label_filename
                    label_path.touch()
    
    def train(self) -> str:
        """
        è®­ç»ƒYOLOv10æ¨¡å‹
        
        Returns:
            æœ€ä½³æ¨¡å‹æƒé‡è·¯å¾„
        """
        print("ğŸš€ Starting YOLOv10 training...")
        
        # å‡†å¤‡æ•°æ®é›†
        dataset_config_path = self.prepare_yolo_dataset()
        
        # åˆå§‹åŒ–æ¨¡å‹
        model_name = self.config.get('model', 'yolov10n.pt')
        model = YOLO(model_name)
        
        # è®­ç»ƒå‚æ•°
        train_args = {
            'data': dataset_config_path,
            'epochs': self.config.get('epochs', 100),
            'imgsz': self.config.get('image_size', 640),
            'batch': self.config.get('batch_size', 16),
            'lr0': self.config.get('learning_rate', 0.01),
            'weight_decay': self.config.get('weight_decay', 0.0005),
            'momentum': self.config.get('momentum', 0.937),
            'patience': self.config.get('patience', 50),
            'save_period': self.config.get('save_period', 10),
            'project': str(self.checkpoint_dir),
            'name': self.config.get('experiment_name', 'meter_detection'),
            'exist_ok': True,
            'pretrained': True,
            'optimize': True,
            'verbose': True,
            'seed': self.config.get('seed', 42),
            'deterministic': True,
            'single_cls': True,  # å•ç±»åˆ«æ£€æµ‹
            'device': self._get_device(),
            'workers': self.config.get('workers', 8),
            'cos_lr': self.config.get('cos_lr', False),
            'close_mosaic': self.config.get('close_mosaic', 10),
            'amp': self.config.get('amp', True),
        }
        
        # æ•°æ®å¢å¼ºå‚æ•°
        augment_args = self.config.get('augmentation', {})
        train_args.update({
            'hsv_h': augment_args.get('hsv_h', 0.015),
            'hsv_s': augment_args.get('hsv_s', 0.7),
            'hsv_v': augment_args.get('hsv_v', 0.4),
            'degrees': augment_args.get('degrees', 0.0),
            'translate': augment_args.get('translate', 0.1),
            'scale': augment_args.get('scale', 0.5),
            'shear': augment_args.get('shear', 0.0),
            'perspective': augment_args.get('perspective', 0.0),
            'flipud': augment_args.get('flipud', 0.0),
            'fliplr': augment_args.get('fliplr', 0.5),
            'mosaic': augment_args.get('mosaic', 1.0),
            'mixup': augment_args.get('mixup', 0.0),
            'copy_paste': augment_args.get('copy_paste', 0.0),
        })
        
        print(f"ğŸ“Š Training configuration:")
        for key, value in train_args.items():
            print(f"  {key}: {value}")
        
        # å¼€å§‹è®­ç»ƒ
        try:
            results = model.train(**train_args)
            
            # è·å–æœ€ä½³æ¨¡å‹è·¯å¾„
            best_model_path = Path(results.save_dir) / "weights" / "best.pt"
            
            print(f"âœ… Training completed!")
            print(f"ğŸ“ Best model saved at: {best_model_path}")
            
            return str(best_model_path)
            
        except Exception as e:
            print(f"âŒ Training failed: {str(e)}")
            raise
    
    def evaluate(self, model_path: str) -> Dict:
        """
        è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹æƒé‡è·¯å¾„
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        print("ğŸ“Š Evaluating model...")
        
        # åŠ è½½æ¨¡å‹
        model = YOLO(model_path)
        
        # å‡†å¤‡éªŒè¯æ•°æ®
        dataset_config_path = self.project_root / "data" / "detection_yolo" / "dataset.yaml"
        
        # è¿è¡ŒéªŒè¯
        results = model.val(
            data=str(dataset_config_path),
            imgsz=self.config.get('image_size', 640),
            batch=self.config.get('batch_size', 16),
            conf=0.001,
            iou=0.6,
            max_det=300,
            device=self._get_device(),
            save_json=True,
            save_hybrid=True,
            plots=True,
            verbose=True
        )
        
        # æå–è¯„ä¼°æŒ‡æ ‡
        metrics = {
            'mAP50': float(results.box.map50),
            'mAP50-95': float(results.box.map),
            'precision': float(results.box.mp),
            'recall': float(results.box.mr),
            'f1_score': 2 * (float(results.box.mp) * float(results.box.mr)) / (float(results.box.mp) + float(results.box.mr)) if (float(results.box.mp) + float(results.box.mr)) > 0 else 0
        }
        
        print(f"ğŸ“ˆ Evaluation Results:")
        for metric, value in metrics.items():
            print(f"  {metric}: {value:.4f}")
        
        # ä¿å­˜è¯„ä¼°ç»“æœ
        results_file = self.result_dir / "evaluation_results.json"
        with open(results_file, 'w') as f:
            json.dump(metrics, f, indent=2)
        
        return metrics
    
    def visualize_predictions(self, model_path: str, num_samples: int = 10):
        """
        å¯è§†åŒ–æ¨¡å‹é¢„æµ‹ç»“æœ
        
        Args:
            model_path: æ¨¡å‹æƒé‡è·¯å¾„
            num_samples: å¯è§†åŒ–æ ·æœ¬æ•°é‡
        """
        print("ğŸ¨ Visualizing predictions...")
        
        # åŠ è½½æ¨¡å‹
        model = YOLO(model_path)
        
        # è·å–éªŒè¯å›¾åƒ
        val_image_dir = self.project_root / "data" / "detection_yolo" / "images" / "val"
        image_files = list(val_image_dir.glob("*.jpg"))[:num_samples]
        
        # åˆ›å»ºå¯è§†åŒ–ç›®å½•
        viz_dir = self.result_dir / "visualizations"
        viz_dir.mkdir(exist_ok=True)
        
        for i, image_path in enumerate(image_files):
            # é¢„æµ‹
            results = model(str(image_path), conf=0.5)
            
            # ç»˜åˆ¶ç»“æœ
            annotated_img = results[0].plot()
            
            # ä¿å­˜å¯è§†åŒ–ç»“æœ
            output_path = viz_dir / f"prediction_{i+1}_{image_path.name}"
            cv2.imwrite(str(output_path), annotated_img)
        
        print(f"âœ… Visualizations saved to: {viz_dir}")
    
    def export_model(self, model_path: str, formats: List[str] = ['onnx']):
        """
        å¯¼å‡ºæ¨¡å‹åˆ°ä¸åŒæ ¼å¼
        
        Args:
            model_path: æ¨¡å‹æƒé‡è·¯å¾„
            formats: å¯¼å‡ºæ ¼å¼åˆ—è¡¨
        """
        print("ğŸ“¦ Exporting model...")
        
        model = YOLO(model_path)
        
        for format_name in formats:
            try:
                print(f"  Exporting to {format_name.upper()}...")
                exported_model = model.export(
                    format=format_name,
                    imgsz=self.config.get('image_size', 640),
                    optimize=True,
                    half=False,
                    int8=False,
                    dynamic=False,
                    simplify=True,
                    opset=None,
                    workspace=4,
                    nms=False
                )
                print(f"  âœ… {format_name.upper()} model exported: {exported_model}")
            except Exception as e:
                print(f"  âŒ Failed to export {format_name}: {str(e)}")


def create_default_config() -> Dict:
    """åˆ›å»ºé»˜è®¤é…ç½®"""
    return {
        'model': 'yolov10n.pt',  # YOLOv10 nanoæ¨¡å‹
        'epochs': 100,
        'batch_size': 16,
        'image_size': 640,
        'learning_rate': 0.01,
        'weight_decay': 0.0005,
        'momentum': 0.937,
        'patience': 50,
        'save_period': 10,
        'experiment_name': 'meter_detection',
        'device': '0' if torch.cuda.is_available() else 'cpu',
        'workers': 8,
        'seed': 42,
        'cos_lr': False,
        'close_mosaic': 10,
        'amp': True,
        'augmentation': {
            'hsv_h': 0.015,
            'hsv_s': 0.7,
            'hsv_v': 0.4,
            'degrees': 0.0,
            'translate': 0.1,
            'scale': 0.5,
            'shear': 0.0,
            'perspective': 0.0,
            'flipud': 0.0,
            'fliplr': 0.5,
            'mosaic': 1.0,
            'mixup': 0.0,
            'copy_paste': 0.0
        }
    }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='YOLOv10 ä»ªè¡¨æ£€æµ‹è®­ç»ƒè„šæœ¬')
    parser.add_argument('--config', type=str, default='config/detection_config.yaml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--create-config', action='store_true',
                       help='åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶')
    parser.add_argument('--eval-only', action='store_true',
                       help='åªè¿è¡Œè¯„ä¼°')
    parser.add_argument('--model-path', type=str,
                       help='é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼ˆç”¨äºè¯„ä¼°ï¼‰')
    parser.add_argument('--visualize', action='store_true',
                       help='å¯è§†åŒ–é¢„æµ‹ç»“æœ')
    parser.add_argument('--export', action='store_true',
                       help='å¯¼å‡ºæ¨¡å‹')
    parser.add_argument('--export-formats', nargs='+', default=['onnx'],
                       help='å¯¼å‡ºæ ¼å¼åˆ—è¡¨')
    
    args = parser.parse_args()
    
    # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
    if args.create_config:
        config_path = Path(args.config)
        config_path.parent.mkdir(parents=True, exist_ok=True)
        
        default_config = create_default_config()
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(default_config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"âœ… Default configuration created at: {config_path}")
        return
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not Path(args.config).exists():
        print(f"âŒ Configuration file not found: {args.config}")
        print("ğŸ’¡ Use --create-config to create a default configuration file")
        return
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨
    trainer = MeterDetectionTrainer(args.config)
    
    try:
        if args.eval_only:
            # åªè¿è¡Œè¯„ä¼°
            if not args.model_path:
                print("âŒ Model path required for evaluation")
                return
            
            metrics = trainer.evaluate(args.model_path)
            
            if args.visualize:
                trainer.visualize_predictions(args.model_path)
            
            if args.export:
                trainer.export_model(args.model_path, args.export_formats)
        
        else:
            # è¿è¡Œå®Œæ•´è®­ç»ƒæµç¨‹
            best_model_path = trainer.train()
            
            # è¯„ä¼°æ¨¡å‹
            metrics = trainer.evaluate(best_model_path)
            
            if args.visualize:
                trainer.visualize_predictions(best_model_path)
            
            if args.export:
                trainer.export_model(best_model_path, args.export_formats)
            
            print("ğŸ‰ Training pipeline completed successfully!")
            print(f"ğŸ“ Best model: {best_model_path}")
            print(f"ğŸ“Š Final mAP@0.5: {metrics['mAP50']:.4f}")
    
    except Exception as e:
        print(f"âŒ Error: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main() 