#!/usr/bin/env python3
"""
æ¶²æ™¶æ•°å­—å±å¹•å¢å¼ºè„šæœ¬

ä¸“é—¨ç”¨äºå¢å¼ºæ¶²æ™¶å±æ˜¾ç¤ºçš„æ•°å­—ï¼Œè§£å†³åå…‰ã€å¯¹æ¯”åº¦ä½ã€æ˜¾ç¤ºä¸æ¸…æ™°ç­‰é—®é¢˜ã€‚
åŒ…å«å¤šç§å›¾åƒå¤„ç†æŠ€æœ¯æ¥æå–å’Œå¢å¼ºæ•°å­—ä¿¡æ¯ã€‚

åŠŸèƒ½ç‰¹æ€§ï¼š
1. åå…‰å»é™¤å’Œå…‰ç…§å‡è¡¡
2. å¯¹æ¯”åº¦å’Œæ¸…æ™°åº¦å¢å¼º
3. æ•°å­—åŒºåŸŸåˆ†å‰²å’Œæå–
4. å¤šç§å¢å¼ºç®—æ³•ç»„åˆ
5. ç»“æœå¯¹æ¯”å’Œå¯è§†åŒ–

ä½œè€…: chijiang
æ—¥æœŸ: 2025-06-09
"""

import os
import sys
import cv2
import json
import argparse
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Union
from tqdm import tqdm
import warnings

warnings.filterwarnings('ignore')

class DigitalDisplayEnhancer:
    """æ¶²æ™¶æ•°å­—æ˜¾ç¤ºå¢å¼ºå™¨"""
    
    def __init__(self, output_dir: None | Path = None):
        """åˆå§‹åŒ–å¢å¼ºå™¨"""
        self.project_root = self._get_project_root()
        self.setup_output_dirs(output_dir)
        
        print("ğŸ¨ æ¶²æ™¶æ•°å­—æ˜¾ç¤ºå¢å¼ºå™¨å·²åˆå§‹åŒ–")
        print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        print(f"ğŸ“Š è¾“å‡ºç›®å½•: {self.output_dir}")
    
    def _get_project_root(self) -> Path:
        """æ™ºèƒ½è·å–é¡¹ç›®æ ¹ç›®å½•"""
        current_dir = Path.cwd()
        if current_dir.name == "enhancement":
            return current_dir.parent.parent.parent
        elif current_dir.name == "digital_meter_detection":
            return current_dir.parent.parent
        elif current_dir.name == "scripts":
            return current_dir.parent
        else:
            return current_dir
    
    def setup_output_dirs(self, output_dir: Path | None):
        """è®¾ç½®è¾“å‡ºç›®å½•"""
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # è¾“å‡ºç›®å½•ç»“æ„
        if output_dir is None:
            self.output_root = self.project_root / "outputs" / "digital_enhancement"
        else:
            self.output_root = output_dir
        self.output_dir = self.output_root / f"enhancement_{self.timestamp}"
        self.original_dir = self.output_dir / "1_original"
        self.enhanced_dir = self.output_dir / "2_enhanced" 
        self.comparison_dir = self.output_dir / "3_comparison"
        self.analysis_dir = self.output_dir / "4_analysis"
        
        # åˆ›å»ºç›®å½•
        for dir_path in [self.original_dir, self.enhanced_dir, self.comparison_dir, self.analysis_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
    
    def remove_glare_and_reflections(self, image: np.ndarray) -> np.ndarray:
        """å»é™¤åå…‰å’Œåå°„"""
        # è½¬æ¢ä¸ºLABé¢œè‰²ç©ºé—´
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l_channel = lab[:, :, 0]
        
        # æ£€æµ‹é«˜äº®åŒºåŸŸï¼ˆåå…‰ï¼‰
        _, glare_mask = cv2.threshold(l_channel, 200, 255, cv2.THRESH_BINARY)
        
        # ä½¿ç”¨å½¢æ€å­¦æ“ä½œä¼˜åŒ–mask
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        glare_mask = cv2.morphologyEx(glare_mask, cv2.MORPH_CLOSE, kernel)
        
        # å¯¹åå…‰åŒºåŸŸè¿›è¡Œä¿®å¤
        if np.sum(glare_mask) > 0:
            result = cv2.inpaint(image, glare_mask, 3, cv2.INPAINT_TELEA)
        else:
            result = image.copy()
        
        return result
    
    def normalize_illumination(self, image: np.ndarray) -> np.ndarray:
        """å…‰ç…§å½’ä¸€åŒ–"""
        # è½¬æ¢ä¸ºç°åº¦
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # ä½¿ç”¨é«˜æ–¯æ»¤æ³¢ä¼°è®¡èƒŒæ™¯å…‰ç…§
        blurred = cv2.GaussianBlur(gray, (51, 51), 0)
        
        # è®¡ç®—å½’ä¸€åŒ–åçš„å›¾åƒ
        normalized = np.zeros_like(gray, dtype=np.float32)
        normalized = cv2.divide(gray.astype(np.float32), blurred.astype(np.float32) + 1e-6)
        
        # å°†ç»“æœç¼©æ”¾åˆ°0-255èŒƒå›´
        normalized = cv2.normalize(normalized, None, 0, 255, cv2.NORM_MINMAX)
        normalized = normalized.astype(np.uint8)
        
        # å¦‚æœåŸå›¾æ˜¯å½©è‰²çš„ï¼Œåº”ç”¨åˆ°æ‰€æœ‰é€šé“
        if len(image.shape) == 3:
            result = image.copy().astype(np.float32)
            for i in range(3):
                channel = image[:, :, i].astype(np.float32)
                blurred_channel = cv2.GaussianBlur(channel, (51, 51), 0)
                result[:, :, i] = cv2.divide(channel, blurred_channel + 1e-6)
            
            result = cv2.normalize(result, None, 0, 255, cv2.NORM_MINMAX)
            result = result.astype(np.uint8)
        else:
            result = normalized
        
        return result
    
    def enhance_contrast_clahe(self, image: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨CLAHEå¢å¼ºå¯¹æ¯”åº¦"""
        if len(image.shape) == 3:
            # è½¬æ¢ä¸ºLABé¢œè‰²ç©ºé—´
            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
            l_channel = lab[:, :, 0]
            
            # å¯¹Lé€šé“åº”ç”¨CLAHE
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
            l_channel = clahe.apply(l_channel)
            
            # é‡æ–°ç»„åˆ
            lab[:, :, 0] = l_channel
            result = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
        else:
            # ç°åº¦å›¾åƒç›´æ¥åº”ç”¨CLAHE
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
            result = clahe.apply(image)
        
        return result
    
    def sharpen_image(self, image: np.ndarray) -> np.ndarray:
        """å›¾åƒé”åŒ–"""
        # ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­è¿›è¡Œé”åŒ–
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # æ‹‰æ™®æ‹‰æ–¯é”åŒ–æ ¸
        kernel = np.array([[-1, -1, -1],
                          [-1,  9, -1],
                          [-1, -1, -1]])
        
        sharpened = cv2.filter2D(gray, -1, kernel)
        
        # å¦‚æœåŸå›¾æ˜¯å½©è‰²çš„ï¼Œå°†é”åŒ–æ•ˆæœåº”ç”¨åˆ°åŸå›¾
        if len(image.shape) == 3:
            # å°†é”åŒ–åçš„ç°åº¦å›¾è½¬æ¢ä¸ºä¸‰é€šé“
            sharpened_3ch = cv2.cvtColor(sharpened, cv2.COLOR_GRAY2BGR)
            # æ··åˆåŸå›¾å’Œé”åŒ–å›¾
            result = cv2.addWeighted(image, 0.7, sharpened_3ch, 0.3, 0)
        else:
            result = sharpened
        
        return result
    
    def extract_digital_region(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """æå–æ•°å­—æ˜¾ç¤ºåŒºåŸŸ"""
        # è½¬æ¢ä¸ºç°åº¦
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # ä½¿ç”¨å¤šç§é˜ˆå€¼æ–¹æ³•
        # 1. Otsué˜ˆå€¼
        _, thresh_otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # 2. è‡ªé€‚åº”é˜ˆå€¼
        thresh_adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                               cv2.THRESH_BINARY, 11, 2)
        
        # 3. åå‘é˜ˆå€¼ï¼ˆå¯¹äºæš—èƒŒæ™¯äº®æ–‡å­—ï¼‰
        _, thresh_inv = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        # å½¢æ€å­¦æ“ä½œæ¸…ç†å™ªå£°
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        
        thresh_otsu = cv2.morphologyEx(thresh_otsu, cv2.MORPH_CLOSE, kernel)
        thresh_adaptive = cv2.morphologyEx(thresh_adaptive, cv2.MORPH_CLOSE, kernel)
        thresh_inv = cv2.morphologyEx(thresh_inv, cv2.MORPH_CLOSE, kernel)
        
        # ç»„åˆå¤šç§é˜ˆå€¼ç»“æœ
        combined = cv2.bitwise_or(thresh_otsu, thresh_adaptive)
        combined = cv2.bitwise_or(combined, thresh_inv)
        
        return combined, gray
    
    def filter_digit_contours(self, binary_image: np.ndarray) -> List[Tuple]:
        """è¿‡æ»¤å‡ºæ•°å­—è½®å»“"""
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # è¿‡æ»¤æ¡ä»¶
        height, width = binary_image.shape
        min_area = (height * width) * 0.001  # æœ€å°é¢ç§¯
        max_area = (height * width) * 0.3    # æœ€å¤§é¢ç§¯
        min_aspect_ratio = 0.1
        max_aspect_ratio = 3.0
        
        digit_contours = []
        
        for contour in contours:
            # è®¡ç®—è½®å»“å±æ€§
            area = cv2.contourArea(contour)
            if area < min_area or area > max_area:
                continue
            
            # è®¡ç®—è¾¹ç•ŒçŸ©å½¢
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = w / h if h > 0 else 0
            
            if aspect_ratio < min_aspect_ratio or aspect_ratio > max_aspect_ratio:
                continue
            
            # è®¡ç®—å¡«å……ç‡
            rect_area = w * h
            fill_ratio = area / rect_area if rect_area > 0 else 0
            
            if fill_ratio < 0.1:  # è¿‡æ»¤æ‰å¤ªç¨€ç–çš„è½®å»“
                continue
            
            digit_contours.append((contour, x, y, w, h, area))
        
        # æŒ‰xåæ ‡æ’åºï¼ˆä»å·¦åˆ°å³ï¼‰
        digit_contours.sort(key=lambda x: x[1])
        
        return digit_contours
    
    def enhance_single_image(self, image: np.ndarray, method: str = "comprehensive") -> Dict:
        """å¢å¼ºå•å¼ å›¾åƒ"""
        results = {}
        
        # ä¿å­˜åŸå›¾
        results['original'] = image.copy()
        
        if method == "comprehensive" or method == "all":
            # ç»¼åˆå¢å¼ºæµç¨‹
            
            # æ­¥éª¤1: å»é™¤åå…‰
            step1 = self.remove_glare_and_reflections(image)
            results['step1_deglare'] = step1
            
            # æ­¥éª¤2: å…‰ç…§å½’ä¸€åŒ–
            step2 = self.normalize_illumination(step1)
            results['step2_illumination'] = step2
            
            # æ­¥éª¤3: å¯¹æ¯”åº¦å¢å¼º
            step3 = self.enhance_contrast_clahe(step2)
            results['step3_contrast'] = step3
            
            # æ­¥éª¤4: å›¾åƒé”åŒ–
            step4 = self.sharpen_image(step3)
            results['step4_sharpen'] = step4
            
            # æ­¥éª¤5: æ•°å­—åŒºåŸŸæå–
            binary, gray = self.extract_digital_region(step4)
            results['step5_binary'] = binary
            results['step5_gray'] = gray
            
            # æ­¥éª¤6: è½®å»“è¿‡æ»¤
            digit_contours = self.filter_digit_contours(binary)
            results['digit_contours'] = digit_contours
            
            # æœ€ç»ˆç»“æœ
            results['final'] = step4
            
        elif method == "deglare_only":
            # ä»…å»åå…‰
            enhanced = self.remove_glare_and_reflections(image)
            results['final'] = enhanced
            
        elif method == "contrast_only":
            # ä»…å¯¹æ¯”åº¦å¢å¼º
            enhanced = self.enhance_contrast_clahe(image)
            results['final'] = enhanced
            
        elif method == "sharpen_only":
            # ä»…é”åŒ–
            enhanced = self.sharpen_image(image)
            results['final'] = enhanced
        
        return results
    
    def create_comparison_visualization(self, results: Dict, output_path: Path):
        """åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–"""
        # åˆ›å»ºå¯¹æ¯”å›¾
        if 'step1_deglare' in results:
            # è¯¦ç»†æ­¥éª¤å¯¹æ¯”
            fig, axes = plt.subplots(2, 4, figsize=(16, 8))
            fig.suptitle('Digital Display Enhancement Process', fontsize=16, fontweight='bold')
            
            # åŸå›¾
            axes[0, 0].imshow(cv2.cvtColor(results['original'], cv2.COLOR_BGR2RGB))
            axes[0, 0].set_title('Original Image')
            axes[0, 0].axis('off')
            
            # å»åå…‰
            axes[0, 1].imshow(cv2.cvtColor(results['step1_deglare'], cv2.COLOR_BGR2RGB))
            axes[0, 1].set_title('Glare Removal')
            axes[0, 1].axis('off')
            
            # å…‰ç…§å½’ä¸€åŒ–
            if len(results['step2_illumination'].shape) == 3:
                axes[0, 2].imshow(cv2.cvtColor(results['step2_illumination'], cv2.COLOR_BGR2RGB))
            else:
                axes[0, 2].imshow(results['step2_illumination'], cmap='gray')
            axes[0, 2].set_title('Illumination Normalization')
            axes[0, 2].axis('off')
            
            # å¯¹æ¯”åº¦å¢å¼º
            if len(results['step3_contrast'].shape) == 3:
                axes[0, 3].imshow(cv2.cvtColor(results['step3_contrast'], cv2.COLOR_BGR2RGB))
            else:
                axes[0, 3].imshow(results['step3_contrast'], cmap='gray')
            axes[0, 3].set_title('Contrast Enhancement')
            axes[0, 3].axis('off')
            
            # å›¾åƒé”åŒ–
            if len(results['step4_sharpen'].shape) == 3:
                axes[1, 0].imshow(cv2.cvtColor(results['step4_sharpen'], cv2.COLOR_BGR2RGB))
            else:
                axes[1, 0].imshow(results['step4_sharpen'], cmap='gray')
            axes[1, 0].set_title('Image Sharpening')
            axes[1, 0].axis('off')
            
            # äºŒå€¼åŒ–
            axes[1, 1].imshow(results['step5_binary'], cmap='gray')
            axes[1, 1].set_title('Digit Extraction')
            axes[1, 1].axis('off')
            
            # è½®å»“æ£€æµ‹
            contour_img = results['original'].copy()
            if 'digit_contours' in results:
                for contour_data in results['digit_contours']:
                    contour, x, y, w, h, area = contour_data
                    cv2.rectangle(contour_img, (x, y), (x+w, y+h), (0, 255, 0), 2)
            
            axes[1, 2].imshow(cv2.cvtColor(contour_img, cv2.COLOR_BGR2RGB))
            axes[1, 2].set_title('Digit Localization')
            axes[1, 2].axis('off')
            
            # æœ€ç»ˆç»“æœ
            if len(results['final'].shape) == 3:
                axes[1, 3].imshow(cv2.cvtColor(results['final'], cv2.COLOR_BGR2RGB))
            else:
                axes[1, 3].imshow(results['final'], cmap='gray')
            axes[1, 3].set_title('Final Result')
            axes[1, 3].axis('off')
            
        else:
            # ç®€å•å‰åå¯¹æ¯”
            fig, axes = plt.subplots(1, 2, figsize=(12, 6))
            fig.suptitle('Digital Display Enhancement Comparison', fontsize=16, fontweight='bold')
            
            # åŸå›¾
            axes[0].imshow(cv2.cvtColor(results['original'], cv2.COLOR_BGR2RGB))
            axes[0].set_title('Original Image')
            axes[0].axis('off')
            
            # å¢å¼ºå
            if len(results['final'].shape) == 3:
                axes[1].imshow(cv2.cvtColor(results['final'], cv2.COLOR_BGR2RGB))
            else:
                axes[1].imshow(results['final'], cmap='gray')
            axes[1].set_title('Enhanced Image')
            axes[1].axis('off')
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
    
    def process_single_image(self, image_path: Union[str, Path], 
                           method: str = "comprehensive") -> Dict:
        """å¤„ç†å•å¼ å›¾åƒ"""
        image_path = Path(image_path)
        
        if not image_path.exists():
            raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        
        print(f"ğŸ¨ å¢å¼ºå›¾åƒ: {image_path.name}")
        
        # åŠ è½½å›¾åƒ
        image = cv2.imread(str(image_path))
        if image is None:
            raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {image_path}")
        
        # æ‰§è¡Œå¢å¼º
        results = self.enhance_single_image(image, method)
        
        # ä¿å­˜ç»“æœ
        image_name = image_path.stem
        
        # ä¿å­˜åŸå›¾
        original_path = self.original_dir / f"{image_name}_original.jpg"
        cv2.imwrite(str(original_path), results['original'])
        
        # ä¿å­˜å¢å¼ºåçš„å›¾åƒ
        enhanced_path = self.enhanced_dir / f"{image_name}_enhanced.jpg"
        cv2.imwrite(str(enhanced_path), results['final'])
        
        # ä¿å­˜äºŒå€¼åŒ–ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
        if 'step5_binary' in results:
            binary_path = self.enhanced_dir / f"{image_name}_binary.jpg"
            cv2.imwrite(str(binary_path), results['step5_binary'])
        
        # åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–
        comparison_path = self.comparison_dir / f"{image_name}_comparison.png"
        self.create_comparison_visualization(results, comparison_path)
        
        return {
            'image_path': str(image_path),
            'image_name': image_name,
            'original_path': str(original_path),
            'enhanced_path': str(enhanced_path),
            'comparison_path': str(comparison_path),
            'method': method,
            'digit_count': len(results.get('digit_contours', [])),
            'timestamp': datetime.now().isoformat()
        }
    
    def process_batch(self, input_path: Union[str, Path], 
                     method: str = "comprehensive") -> List[Dict]:
        """æ‰¹é‡å¤„ç†å›¾åƒ"""
        input_path = Path(input_path)
        
        # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
        if input_path.is_file():
            image_files = [input_path]
        elif input_path.is_dir():
            image_files = []
            for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']:
                image_files.extend(input_path.glob(ext))
                image_files.extend(input_path.glob(ext.upper()))
        else:
            raise ValueError(f"è¾“å…¥è·¯å¾„æ— æ•ˆ: {input_path}")
        
        if not image_files:
            raise ValueError(f"æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {input_path}")
        
        print(f"ğŸ¨ å¼€å§‹æ‰¹é‡å¢å¼ºï¼Œå…± {len(image_files)} å¼ å›¾åƒ")
        
        all_results = []
        
        # å¤„ç†æ¯å¼ å›¾åƒ
        for image_file in tqdm(image_files, desc="å¢å¼ºå›¾åƒ"):
            try:
                result = self.process_single_image(image_file, method)
                all_results.append(result)
            except Exception as e:
                print(f"âš ï¸  å¤„ç† {image_file.name} æ—¶å‡ºé”™: {e}")
                continue
        
        return all_results
    
    def save_results(self, all_results: List[Dict]):
        """ä¿å­˜å¤„ç†ç»“æœ"""
        print("\nğŸ’¾ ä¿å­˜å¢å¼ºç»“æœ...")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_file = self.output_dir / "enhancement_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        summary = {
            'total_images': len(all_results),
            'successful_enhancements': len(all_results),
            'output_directories': {
                'original': str(self.original_dir),
                'enhanced': str(self.enhanced_dir),
                'comparison': str(self.comparison_dir),
                'analysis': str(self.analysis_dir)
            },
            'timestamp': datetime.now().isoformat()
        }
        
        summary_file = self.output_dir / "enhancement_summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        self._generate_markdown_report(summary, all_results)
        
        print(f"âœ… ç»“æœä¿å­˜å®Œæˆ:")
        print(f"  - è¯¦ç»†ç»“æœ: {results_file}")
        print(f"  - å¢å¼ºæ€»ç»“: {summary_file}")
    
    def _generate_markdown_report(self, summary: Dict, all_results: List[Dict]):
        """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
        md_content = f"""# Digital Display Enhancement Report

## Processing Summary
- **Total Images**: {summary['total_images']}
- **Successfully Enhanced**: {summary['successful_enhancements']}
- **Processing Time**: {summary['timestamp'][:19].replace('T', ' ')}

## Output Directories
- **Original Images**: `1_original/`
- **Enhanced Images**: `2_enhanced/`
- **Comparison Images**: `3_comparison/`
- **Analysis Results**: `4_analysis/`

## Processing Methods
This enhancement uses a comprehensive processing pipeline:

1. **Glare Removal**: Detect and repair high-brightness reflection areas
2. **Illumination Normalization**: Balance image illumination distribution
3. **Contrast Enhancement**: Use CLAHE algorithm to enhance local contrast
4. **Image Sharpening**: Use Laplacian operator to enhance edges
5. **Digit Extraction**: Multi-threshold methods to extract digit regions
6. **Contour Filtering**: Filter digit contours based on geometric features

## Technical Features
- **Multi-step Processing**: Specialized optimization for LCD display characteristics
- **Reflection Handling**: Effectively remove LCD display reflection issues
- **Contrast Optimization**: Enhance contrast between digits and background
- **Edge Enhancement**: Improve digit boundary clarity

## File Description
Each image generates the following files:
- `*_original.jpg`: Original image
- `*_enhanced.jpg`: Final enhanced image
- `*_binary.jpg`: Digit binarized image
- `*_comparison.png`: Processing steps comparison chart

---
*Report generated at: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
"""
        
        md_file = self.output_dir / "enhancement_report.md"
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(md_content)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ¶²æ™¶æ•°å­—å±å¹•å¢å¼ºè„šæœ¬')
    parser.add_argument('--input', type=str, required=True,
                       help='è¾“å…¥å›¾åƒæ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--method', type=str, default='comprehensive',
                       choices=['comprehensive', 'deglare_only', 'contrast_only', 'sharpen_only'],
                       help='å¢å¼ºæ–¹æ³• (é»˜è®¤: comprehensive)')
    parser.add_argument('--output', type=str, default='outputs/digital_enhancement',
                       help='è‡ªå®šä¹‰è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    try:
        
        if args.output:
            output_dir = Path(args.output)
            output_dir.mkdir(parents=True, exist_ok=True)
        else:
            output_dir = None
        
        # åˆ›å»ºå¢å¼ºå™¨
        enhancer = DigitalDisplayEnhancer(output_dir=output_dir)

        # å¦‚æœæŒ‡å®šäº†è‡ªå®šä¹‰è¾“å‡ºç›®å½•
        if output_dir:
            enhancer.output_dir = output_dir
            enhancer.original_dir = output_dir / "1_original"
            enhancer.enhanced_dir = output_dir / "2_enhanced"
            enhancer.comparison_dir = output_dir / "3_comparison"
            enhancer.analysis_dir = output_dir / "4_analysis"
            
            for dir_path in [enhancer.original_dir, enhancer.enhanced_dir, 
                           enhancer.comparison_dir, enhancer.analysis_dir]:
                dir_path.mkdir(parents=True, exist_ok=True)
        
        
        
        # æ‰¹é‡å¤„ç†
        results = enhancer.process_batch(args.input, args.method)
        
        # ä¿å­˜ç»“æœ
        enhancer.save_results(results)
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ‰ å¢å¼ºå®Œæˆ!")
        print(f"ğŸ“Š å¤„ç†å›¾åƒ: {len(results)} å¼ ")
        print(f"ğŸ“ ç»“æœç›®å½•: {enhancer.output_dir}")
        print(f"ğŸ¨ å¢å¼ºæ–¹æ³•: {args.method}")
        
    except Exception as e:
        print(f"âŒ å¢å¼ºè¿‡ç¨‹å‡ºé”™: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main() 