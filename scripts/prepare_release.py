#!/usr/bin/env python3
"""
å‡†å¤‡é¡¹ç›®å‘å¸ƒï¼šæ‰“åŒ…æ•°æ®é›†å’Œæ¨¡å‹
"""

import os
import shutil
import zipfile
import tarfile
from pathlib import Path
import json

def create_data_archive():
    """åˆ›å»ºæ•°æ®é›†å‹ç¼©åŒ…"""
    print("ğŸ“¦ åˆ›å»ºæ•°æ®é›†å‹ç¼©åŒ…...")
    
    # æ£€æµ‹æ•°æ®é›†
    if os.path.exists("data/detection"):
        with zipfile.ZipFile("releases/detection_dataset.zip", 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk("data/detection"):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, "data")
                    zipf.write(file_path, arcname)
        print("âœ… æ£€æµ‹æ•°æ®é›†æ‰“åŒ…å®Œæˆ: releases/detection_dataset.zip")
    
    # åˆ†å‰²æ•°æ®é›†
    if os.path.exists("data/segmentation"):
        with zipfile.ZipFile("releases/segmentation_dataset.zip", 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk("data/segmentation"):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, "data")
                    zipf.write(file_path, arcname)
        print("âœ… åˆ†å‰²æ•°æ®é›†æ‰“åŒ…å®Œæˆ: releases/segmentation_dataset.zip")

def create_model_archive():
    """åˆ›å»ºæ¨¡å‹å‹ç¼©åŒ…"""
    print("ğŸ“¦ åˆ›å»ºæ¨¡å‹å‹ç¼©åŒ…...")
    
    model_files = []
    
    # æ£€æµ‹æ¨¡å‹
    detection_paths = [
        "outputs/checkpoints/detection/meter_detection_v1/weights/best.pt",
        "models/detection/detection_model.pt"
    ]
    
    for path in detection_paths:
        if os.path.exists(path):
            model_files.append((path, f"detection/{Path(path).name}"))
            break
    
    # åˆ†å‰²æ¨¡å‹
    segmentation_paths = [
        "outputs/segmentation/exported/segmentation_model.onnx",
        "outputs/segmentation/checkpoints/best_model.pth"
    ]
    
    for path in segmentation_paths:
        if os.path.exists(path):
            model_files.append((path, f"segmentation/{Path(path).name}"))
    
    if model_files:
        with zipfile.ZipFile("releases/trained_models.zip", 'w', zipfile.ZIP_DEFLATED) as zipf:
            for src_path, arc_name in model_files:
                zipf.write(src_path, arc_name)
        print("âœ… æ¨¡å‹æ‰“åŒ…å®Œæˆ: releases/trained_models.zip")
    else:
        print("âš ï¸  æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")

def create_release_info():
    """åˆ›å»ºå‘å¸ƒä¿¡æ¯æ–‡ä»¶"""
    release_info = {
        "version": "v1.0.0",
        "release_date": "2025-01-XX",
        "description": "å·¥ä¸šæŒ‡é’ˆå¼ä»ªè¡¨è¯»æ•°è¯†åˆ«ç³»ç»Ÿå®Œæ•´ç‰ˆæœ¬",
        "components": {
            "detection_model": {
                "architecture": "YOLOv10",
                "dataset_size": "1836 images",
                "performance": "mAP@0.5 > 0.85"
            },
            "segmentation_model": {
                "architecture": "DeepLabV3+ (ResNet50)",
                "format": "ONNX",
                "classes": ["background", "pointer", "scale"],
                "performance": "mIoU > 0.75"
            },
            "reading_algorithm": {
                "method": "Geometric analysis",
                "accuracy": "< 5% error"
            }
        },
        "files": {
            "detection_dataset.zip": "æ£€æµ‹æ•°æ®é›† (COCOæ ¼å¼)",
            "segmentation_dataset.zip": "åˆ†å‰²æ•°æ®é›† (Pascal VOCæ ¼å¼)",
            "trained_models.zip": "é¢„è®­ç»ƒæ¨¡å‹æƒé‡",
            "source_code.zip": "å®Œæ•´æºä»£ç "
        },
        "usage": {
            "web_app": "python app.py",
            "training": "python scripts/train_detection.py",
            "inference": "å‚è€ƒREADME.md"
        },
        "requirements": {
            "python": ">=3.8",
            "torch": ">=2.0.0",
            "memory": ">=4GB",
            "storage": ">=2GB"
        },
        "license": "MIT",
        "author": "chijiang",
        "repository": "https://github.com/chijiang/pointerMeterReader"
    }
    
    with open("releases/release_info.json", 'w', encoding='utf-8') as f:
        json.dump(release_info, f, ensure_ascii=False, indent=2)
    
    print("âœ… å‘å¸ƒä¿¡æ¯åˆ›å»ºå®Œæˆ: releases/release_info.json")

def create_source_archive():
    """åˆ›å»ºæºä»£ç å‹ç¼©åŒ…"""
    print("ğŸ“¦ åˆ›å»ºæºä»£ç å‹ç¼©åŒ…...")
    
    # è¦åŒ…å«çš„æ–‡ä»¶å’Œç›®å½•
    include_patterns = [
        "*.py",
        "*.md",
        "*.txt",
        "*.yaml",
        "*.yml",
        "config/",
        "scripts/",
        "tools/",
        "LICENSE"
    ]
    
    # è¦æ’é™¤çš„æ–‡ä»¶å’Œç›®å½•
    exclude_patterns = [
        "__pycache__/",
        "*.pyc",
        ".git/",
        ".venv/",
        "outputs/",
        "data/",
        "models/",
        "releases/",
        ".DS_Store",
        "*.log"
    ]
    
    with zipfile.ZipFile("releases/source_code.zip", 'w', zipfile.ZIP_DEFLATED) as zipf:
        for root, dirs, files in os.walk("."):
            # è¿‡æ»¤ç›®å½•
            dirs[:] = [d for d in dirs if not any(d.startswith(pattern.rstrip('/')) for pattern in exclude_patterns)]
            
            for file in files:
                file_path = os.path.join(root, file)
                rel_path = os.path.relpath(file_path, ".")
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤
                should_exclude = any(
                    pattern in rel_path or rel_path.endswith(pattern.rstrip('*'))
                    for pattern in exclude_patterns
                )
                
                if not should_exclude:
                    zipf.write(file_path, rel_path)
    
    print("âœ… æºä»£ç æ‰“åŒ…å®Œæˆ: releases/source_code.zip")

def create_download_script():
    """åˆ›å»ºä¸‹è½½è„šæœ¬"""
    download_script = '''#!/bin/bash
# å·¥ä¸šä»ªè¡¨è¯»æ•°è¯†åˆ«ç³»ç»Ÿ - å¿«é€Ÿä¸‹è½½è„šæœ¬

echo "ğŸš€ å¼€å§‹ä¸‹è½½å·¥ä¸šä»ªè¡¨è¯»æ•°è¯†åˆ«ç³»ç»Ÿ..."

# åˆ›å»ºç›®å½•
mkdir -p pointMeterReader
cd pointMeterReader

# ä¸‹è½½æºä»£ç 
echo "ğŸ“¥ ä¸‹è½½æºä»£ç ..."
curl -L -o source_code.zip "https://github.com/chijiang/pointerMeterReader/releases/latest/download/source_code.zip"
unzip source_code.zip
rm source_code.zip

# ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
echo "ğŸ“¥ ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹..."
curl -L -o trained_models.zip "https://github.com/chijiang/pointerMeterReader/releases/latest/download/trained_models.zip"
unzip trained_models.zip -d models/
rm trained_models.zip

# å¯é€‰ï¼šä¸‹è½½æ•°æ®é›†
read -p "æ˜¯å¦ä¸‹è½½è®­ç»ƒæ•°æ®é›†ï¼Ÿ(y/N): " download_data
if [[ $download_data =~ ^[Yy]$ ]]; then
    echo "ğŸ“¥ ä¸‹è½½æ£€æµ‹æ•°æ®é›†..."
    curl -L -o detection_dataset.zip "https://github.com/chijiang/pointerMeterReader/releases/latest/download/detection_dataset.zip"
    unzip detection_dataset.zip -d data/
    rm detection_dataset.zip
    
    echo "ğŸ“¥ ä¸‹è½½åˆ†å‰²æ•°æ®é›†..."
    curl -L -o segmentation_dataset.zip "https://github.com/chijiang/pointerMeterReader/releases/latest/download/segmentation_dataset.zip"
    unzip segmentation_dataset.zip -d data/
    rm segmentation_dataset.zip
fi

# å®‰è£…ä¾èµ–
echo "ğŸ“¦ å®‰è£…Pythonä¾èµ–..."
pip install -r requirements.txt

echo "âœ… ä¸‹è½½å®Œæˆï¼"
echo "ğŸš€ å¯åŠ¨åº”ç”¨: python app.py"
echo "ğŸ“– æŸ¥çœ‹æ–‡æ¡£: cat README.md"
'''
    
    with open("releases/download.sh", 'w') as f:
        f.write(download_script)
    
    # è®¾ç½®æ‰§è¡Œæƒé™
    os.chmod("releases/download.sh", 0o755)
    
    print("âœ… ä¸‹è½½è„šæœ¬åˆ›å»ºå®Œæˆ: releases/download.sh")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å‡†å¤‡é¡¹ç›®å‘å¸ƒ...")
    
    # åˆ›å»ºå‘å¸ƒç›®å½•
    os.makedirs("releases", exist_ok=True)
    
    # åˆ›å»ºå„ç§å‹ç¼©åŒ…
    create_data_archive()
    create_model_archive()
    create_source_archive()
    
    # åˆ›å»ºå‘å¸ƒä¿¡æ¯
    create_release_info()
    create_download_script()
    
    print("\nâœ… å‘å¸ƒå‡†å¤‡å®Œæˆï¼")
    print("\nğŸ“ å‘å¸ƒæ–‡ä»¶:")
    for file in os.listdir("releases"):
        file_path = os.path.join("releases", file)
        size = os.path.getsize(file_path) / (1024*1024)  # MB
        print(f"   {file} ({size:.1f} MB)")
    
    print("\nğŸ“‹ ä¸‹ä¸€æ­¥:")
    print("1. æ£€æŸ¥releases/ç›®å½•ä¸­çš„æ–‡ä»¶")
    print("2. åˆ›å»ºGitHub Releaseå¹¶ä¸Šä¼ æ–‡ä»¶")
    print("3. æˆ–è¿è¡Œ: python scripts/upload_to_huggingface.py")

if __name__ == "__main__":
    main() 