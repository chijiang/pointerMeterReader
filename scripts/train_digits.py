#!/usr/bin/env python3
"""
YOLOv10 æ¶²æ™¶æ•°å­—è¡¨æ£€æµ‹æ¨¡å‹è®­ç»ƒè„šæœ¬

æ­¤è„šæœ¬ç”¨äºè®­ç»ƒYOLOv10æ¨¡å‹æ¥æ£€æµ‹å’Œè¯†åˆ«æ¶²æ™¶æ•°å­—è¡¨ä¸­çš„æ•°å­—å’Œå°æ•°ç‚¹ã€‚
æ”¯æŒå¤šç±»åˆ«æ£€æµ‹ï¼šæ•°å­—0-9å’Œå°æ•°ç‚¹ï¼Œç”¨äºè¯»å–æ¶²æ™¶æ•°å­—è¡¨çš„ç¤ºæ•°ã€‚

ä½œè€…: chijiang
æ—¥æœŸ: 2025-01-15
"""

import os
import sys
import argparse
import yaml
import json
import shutil
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import torch
import cv2
import numpy as np
from ultralytics import YOLO
from ultralytics.utils import LOGGER
from ultralytics.utils.plotting import Annotator, colors
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from sklearn.model_selection import train_test_split
import warnings

warnings.filterwarnings('ignore')

class DigitsDetectionTrainer:
    """æ¶²æ™¶æ•°å­—è¡¨æ£€æµ‹è®­ç»ƒå™¨"""
    
    def __init__(self, config_path: str):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self.load_config(config_path)
        self.project_root = Path(__file__).parent.parent
        self.setup_directories()
        
    def load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        return config
    
    def _get_device(self) -> str:
        """
        æ™ºèƒ½æ£€æµ‹æœ€ä½³è®¾å¤‡
        
        Returns:
            è®¾å¤‡å­—ç¬¦ä¸²
        """
        config_device = self.config.get('device', 'auto')
        
        if config_device != 'auto':
            return config_device
        
        # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
        if torch.cuda.is_available():
            device = '0'
            print(f"ğŸ”¥ Using CUDA GPU: {torch.cuda.get_device_name(0)}")
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            device = 'mps'
            print("ğŸ Using Apple MPS acceleration")
        else:
            device = 'cpu'
            print("ğŸ’» Using CPU")
        
        # è¾“å‡ºè®¾å¤‡ä¿¡æ¯
        print(f"ğŸ¯ Device selected: {device}")
        if device == 'mps':
            print("â„¹ï¸  Apple Silicon detected - using Metal Performance Shaders for acceleration")
        elif device == 'cpu':
            print("âš ï¸  No GPU acceleration available - training will be slower")
            
        return device
    
    def setup_directories(self):
        """è®¾ç½®è¾“å‡ºç›®å½•"""
        self.output_dir = self.project_root / "outputs"
        self.checkpoint_dir = self.output_dir / "checkpoints" / "digits"
        self.log_dir = self.output_dir / "logs" / "digits"
        self.result_dir = self.output_dir / "results" / "digits"
        
        # åˆ›å»ºç›®å½•
        for dir_path in [self.checkpoint_dir, self.log_dir, self.result_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
    
    def prepare_yolo_dataset(self) -> str:
        """
        å‡†å¤‡YOLOæ ¼å¼æ•°æ®é›†ï¼Œå°†æ•°æ®åˆ†å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†
        
        Returns:
            YOLOæ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
        """
        print("ğŸ”„ Preparing YOLO dataset for digit detection...")
        
        # æ•°æ®è·¯å¾„
        data_root = self.project_root / "data" / "digits"
        yolo_root = self.project_root / "data" / "digits_yolo"
        
        # åˆ›å»ºYOLOæ ¼å¼ç›®å½•
        yolo_root.mkdir(exist_ok=True)
        (yolo_root / "images" / "train").mkdir(parents=True, exist_ok=True)
        (yolo_root / "images" / "val").mkdir(parents=True, exist_ok=True)
        (yolo_root / "labels" / "train").mkdir(parents=True, exist_ok=True)
        (yolo_root / "labels" / "val").mkdir(parents=True, exist_ok=True)
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_dir = data_root / "images"
        label_dir = data_root / "labels"
        
        image_files = list(image_dir.glob("*.jpg"))
        
        # è¿‡æ»¤å‡ºæœ‰å¯¹åº”æ ‡æ³¨æ–‡ä»¶çš„å›¾åƒ
        valid_images = []
        for img_file in image_files:
            label_file = label_dir / (img_file.stem + ".txt")
            if label_file.exists():
                valid_images.append(img_file)
        
        print(f"ğŸ“Š Found {len(valid_images)} valid image-label pairs")
        
        # åˆ†å‰²æ•°æ®é›†
        train_split = self.config.get('train_split', 0.8)
        train_images, val_images = train_test_split(
            valid_images, 
            train_size=train_split, 
            random_state=self.config.get('seed', 42)
        )
        
        print(f"ğŸ“ Training set: {len(train_images)} images")
        print(f"ğŸ“ Validation set: {len(val_images)} images")
        
        # å¤åˆ¶è®­ç»ƒæ•°æ®
        self._copy_dataset(train_images, data_root, yolo_root, "train")
        # å¤åˆ¶éªŒè¯æ•°æ®
        self._copy_dataset(val_images, data_root, yolo_root, "val")
        
        # åˆ›å»ºæ•°æ®é›†é…ç½®æ–‡ä»¶
        # ä»classes.txtè¯»å–ç±»åˆ«ä¿¡æ¯
        classes_file = data_root / "classes.txt"
        with open(classes_file, 'r', encoding='utf-8') as f:
            class_names = [line.strip() for line in f.readlines() if line.strip()]
        
        dataset_config = {
            'train': str(yolo_root / "images" / "train"),
            'val': str(yolo_root / "images" / "val"),
            'nc': len(class_names),  # ç±»åˆ«æ•°é‡
            'names': class_names  # ç±»åˆ«åç§°
        }
        
        config_path = yolo_root / "dataset.yaml"
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(dataset_config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"âœ… Dataset configuration saved to: {config_path}")
        print(f"ğŸ“‹ Classes: {class_names}")
        
        return str(config_path)
    
    def _copy_dataset(self, image_files: List[Path], data_root: Path, 
                     yolo_root: Path, split: str):
        """å¤åˆ¶æ•°æ®é›†æ–‡ä»¶"""
        
        for img_file in tqdm(image_files, desc=f"Copying {split} data"):
            # å¤åˆ¶å›¾åƒæ–‡ä»¶
            dst_img_path = yolo_root / "images" / split / img_file.name
            if not dst_img_path.exists():
                shutil.copy2(img_file, dst_img_path)
            
            # å¤åˆ¶æ ‡æ³¨æ–‡ä»¶
            src_label_path = data_root / "labels" / (img_file.stem + ".txt")
            dst_label_path = yolo_root / "labels" / split / (img_file.stem + ".txt")
            if src_label_path.exists() and not dst_label_path.exists():
                shutil.copy2(src_label_path, dst_label_path)
    
    def train(self) -> str:
        """
        è®­ç»ƒYOLOv10æ¨¡å‹
        
        Returns:
            æœ€ä½³æ¨¡å‹æƒé‡è·¯å¾„
        """
        print("ğŸš€ Starting YOLOv10 digit detection training...")
        
        # å‡†å¤‡æ•°æ®é›†
        dataset_config_path = self.prepare_yolo_dataset()
        
        # åˆå§‹åŒ–æ¨¡å‹
        model_name = self.config.get('model', 'yolov10n.pt')
        model = YOLO(model_name)
        
        # è®­ç»ƒå‚æ•°
        train_args = {
            'data': dataset_config_path,
            'epochs': self.config.get('epochs', 100),
            'imgsz': self.config.get('image_size', 640),
            'batch': self.config.get('batch_size', 16),
            'lr0': self.config.get('learning_rate', 0.01),
            'weight_decay': self.config.get('weight_decay', 0.0005),
            'momentum': self.config.get('momentum', 0.937),
            'patience': self.config.get('patience', 50),
            'save_period': self.config.get('save_period', 10),
            'project': str(self.checkpoint_dir),
            'name': self.config.get('experiment_name', 'digit_detection'),
            'exist_ok': True,
            'pretrained': True,
            'optimize': True,
            'verbose': True,
            'seed': self.config.get('seed', 42),
            'deterministic': True,
            'device': self._get_device(),
            'workers': self.config.get('workers', 8),
            'cos_lr': self.config.get('cos_lr', False),
            'close_mosaic': self.config.get('close_mosaic', 10),
            'amp': self.config.get('amp', True),
        }
        
        # æ•°æ®å¢å¼ºå‚æ•°ï¼ˆé’ˆå¯¹æ•°å­—è¯†åˆ«ä¼˜åŒ–ï¼‰
        augment_args = self.config.get('augmentation', {})
        train_args.update({
            'hsv_h': augment_args.get('hsv_h', 0.01),  # è¾ƒå°çš„è‰²è°ƒå˜åŒ–
            'hsv_s': augment_args.get('hsv_s', 0.5),   # é€‚ä¸­çš„é¥±å’Œåº¦å˜åŒ–
            'hsv_v': augment_args.get('hsv_v', 0.3),   # é€‚ä¸­çš„äº®åº¦å˜åŒ–
            'degrees': augment_args.get('degrees', 5.0),  # å°å¹…æ—‹è½¬
            'translate': augment_args.get('translate', 0.05),  # å°å¹…å¹³ç§»
            'scale': augment_args.get('scale', 0.3),    # é€‚ä¸­çš„ç¼©æ”¾
            'shear': augment_args.get('shear', 2.0),    # å°å¹…å‰ªåˆ‡
            'perspective': augment_args.get('perspective', 0.0),  # ä¸ä½¿ç”¨é€è§†å˜æ¢
            'flipud': augment_args.get('flipud', 0.0),  # ä¸è¿›è¡Œä¸Šä¸‹ç¿»è½¬
            'fliplr': augment_args.get('fliplr', 0.0),  # ä¸è¿›è¡Œå·¦å³ç¿»è½¬
            'mosaic': augment_args.get('mosaic', 0.5),  # å‡å°‘é©¬èµ›å…‹å¢å¼º
            'mixup': augment_args.get('mixup', 0.0),    # ä¸ä½¿ç”¨mixup
            'copy_paste': augment_args.get('copy_paste', 0.0),  # ä¸ä½¿ç”¨copy_paste
        })
        
        print(f"ğŸ“Š Training configuration:")
        for key, value in train_args.items():
            print(f"  {key}: {value}")
        
        # å¼€å§‹è®­ç»ƒ
        try:
            results = model.train(**train_args)
            
            # è·å–æœ€ä½³æ¨¡å‹è·¯å¾„
            best_model_path = Path(results.save_dir) / "weights" / "best.pt"
            
            print(f"âœ… Training completed!")
            print(f"ğŸ“ Best model saved at: {best_model_path}")
            
            return str(best_model_path)
            
        except Exception as e:
            print(f"âŒ Training failed: {str(e)}")
            raise
    
    def evaluate(self, model_path: str) -> Dict:
        """
        è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹æƒé‡è·¯å¾„
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        print("ğŸ“Š Evaluating digit detection model...")
        
        # åŠ è½½æ¨¡å‹
        model = YOLO(model_path)
        
        # å‡†å¤‡éªŒè¯æ•°æ®
        dataset_config_path = self.project_root / "data" / "digits_yolo" / "dataset.yaml"
        
        # è¿è¡ŒéªŒè¯
        results = model.val(
            data=str(dataset_config_path),
            imgsz=self.config.get('image_size', 640),
            batch=self.config.get('batch_size', 16),
            conf=0.001,
            iou=0.6,
            max_det=300,
            device=self._get_device(),
            save_json=True,
            save_hybrid=True,
            plots=True,
            verbose=True
        )
        
        # æå–è¯„ä¼°æŒ‡æ ‡
        metrics = {
            'mAP50': float(results.box.map50),
            'mAP50-95': float(results.box.map),
            'precision': float(results.box.mp),
            'recall': float(results.box.mr),
            'f1_score': 2 * (float(results.box.mp) * float(results.box.mr)) / (float(results.box.mp) + float(results.box.mr)) if (float(results.box.mp) + float(results.box.mr)) > 0 else 0
        }
        
        print(f"ğŸ“ˆ Evaluation Results:")
        for metric, value in metrics.items():
            print(f"  {metric}: {value:.4f}")
        
        # ä¿å­˜è¯„ä¼°ç»“æœ
        results_file = self.result_dir / "evaluation_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, indent=2)
        
        return metrics
    
    def visualize_predictions(self, model_path: str, num_samples: int = 10):
        """
        å¯è§†åŒ–æ¨¡å‹é¢„æµ‹ç»“æœ
        
        Args:
            model_path: æ¨¡å‹æƒé‡è·¯å¾„
            num_samples: å¯è§†åŒ–æ ·æœ¬æ•°é‡
        """
        print("ğŸ¨ Visualizing digit detection predictions...")
        
        # åŠ è½½æ¨¡å‹
        model = YOLO(model_path)
        
        # è·å–éªŒè¯å›¾åƒ
        val_image_dir = self.project_root / "data" / "digits_yolo" / "images" / "val"
        image_files = list(val_image_dir.glob("*.jpg"))[:num_samples]
        
        # åˆ›å»ºå¯è§†åŒ–ç›®å½•
        viz_dir = self.result_dir / "visualizations"
        viz_dir.mkdir(exist_ok=True)
        
        for i, image_path in enumerate(image_files):
            # é¢„æµ‹
            results = model(str(image_path), conf=0.3)
            
            # ç»˜åˆ¶ç»“æœ
            annotated_img = results[0].plot()
            
            # ä¿å­˜å¯è§†åŒ–ç»“æœ
            output_path = viz_dir / f"digit_prediction_{i+1}_{image_path.name}"
            cv2.imwrite(str(output_path), annotated_img)
        
        print(f"âœ… Visualizations saved to: {viz_dir}")
    
    def predict_reading(self, model_path: str, image_path: str) -> str:
        """
        é¢„æµ‹æ¶²æ™¶æ•°å­—è¡¨çš„è¯»æ•°
        
        Args:
            model_path: æ¨¡å‹æƒé‡è·¯å¾„
            image_path: å›¾åƒè·¯å¾„
            
        Returns:
            è¯†åˆ«çš„æ•°å­—è¯»æ•°
        """
        print(f"ğŸ” Predicting reading from: {image_path}")
        
        # åŠ è½½æ¨¡å‹
        model = YOLO(model_path)
        
        # é¢„æµ‹
        results = model(image_path, conf=0.3)
        
        # è§£æç»“æœ
        detections = []
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for i in range(len(boxes)):
                    x1, y1, x2, y2 = boxes.xyxy[i].cpu().numpy()
                    conf = boxes.conf[i].cpu().numpy()
                    cls = int(boxes.cls[i].cpu().numpy())
                    
                    # è·å–ç±»åˆ«åç§°
                    class_name = result.names[cls]
                    
                    detections.append({
                        'class': class_name,
                        'confidence': conf,
                        'bbox': [x1, y1, x2, y2],
                        'center_x': (x1 + x2) / 2
                    })
        
        # æŒ‰xåæ ‡æ’åºï¼ˆä»å·¦åˆ°å³ï¼‰
        detections.sort(key=lambda x: x['center_x'])
        
        # æ„å»ºè¯»æ•°å­—ç¬¦ä¸²
        reading = ""
        for det in detections:
            if det['class'] == 'point':
                reading += '.'
            else:
                reading += det['class']
        
        print(f"ğŸ“Š Detected reading: {reading}")
        return reading
    
    def export_model(self, model_path: str, formats: List[str] = ['onnx']):
        """
        å¯¼å‡ºæ¨¡å‹åˆ°ä¸åŒæ ¼å¼
        
        Args:
            model_path: æ¨¡å‹æƒé‡è·¯å¾„
            formats: å¯¼å‡ºæ ¼å¼åˆ—è¡¨
        """
        print("ğŸ“¦ Exporting digit detection model...")
        
        model = YOLO(model_path)
        
        for format_name in formats:
            try:
                print(f"  Exporting to {format_name.upper()}...")
                exported_model = model.export(
                    format=format_name,
                    imgsz=self.config.get('image_size', 640),
                    optimize=True,
                    half=False,
                    int8=False,
                    dynamic=False,
                    simplify=True,
                    opset=None,
                    workspace=4,
                    nms=False
                )
                print(f"  âœ… {format_name.upper()} model exported: {exported_model}")
            except Exception as e:
                print(f"  âŒ Failed to export {format_name}: {str(e)}")


def create_default_config() -> Dict:
    """åˆ›å»ºé»˜è®¤é…ç½®"""
    return {
        'model': 'yolov10n.pt',  # YOLOv10 nanoæ¨¡å‹
        'epochs': 150,
        'batch_size': 16,
        'image_size': 640,
        'learning_rate': 0.01,
        'weight_decay': 0.0005,
        'momentum': 0.937,
        'patience': 50,
        'save_period': 10,
        'train_split': 0.8,
        'experiment_name': 'digit_detection',
        'device': 'auto',
        'workers': 8,
        'seed': 42,
        'cos_lr': False,
        'close_mosaic': 10,
        'amp': True,
        'augmentation': {
            'hsv_h': 0.01,    # å°å¹…è‰²è°ƒå˜åŒ–
            'hsv_s': 0.5,     # é€‚ä¸­é¥±å’Œåº¦å˜åŒ–
            'hsv_v': 0.3,     # é€‚ä¸­äº®åº¦å˜åŒ–
            'degrees': 5.0,   # å°å¹…æ—‹è½¬
            'translate': 0.05, # å°å¹…å¹³ç§»
            'scale': 0.3,     # é€‚ä¸­ç¼©æ”¾
            'shear': 2.0,     # å°å¹…å‰ªåˆ‡
            'perspective': 0.0, # ä¸ä½¿ç”¨é€è§†å˜æ¢
            'flipud': 0.0,    # ä¸ä½¿ç”¨ä¸Šä¸‹ç¿»è½¬
            'fliplr': 0.0,    # ä¸ä½¿ç”¨å·¦å³ç¿»è½¬
            'mosaic': 0.5,    # å‡å°‘é©¬èµ›å…‹å¢å¼º
            'mixup': 0.0,     # ä¸ä½¿ç”¨mixup
            'copy_paste': 0.0  # ä¸ä½¿ç”¨copy_paste
        }
    }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='YOLOv10 æ¶²æ™¶æ•°å­—è¡¨æ£€æµ‹è®­ç»ƒè„šæœ¬')
    parser.add_argument('--config', type=str, default='config/digits_config.yaml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--create-config', action='store_true',
                       help='åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶')
    parser.add_argument('--eval-only', action='store_true',
                       help='åªè¿è¡Œè¯„ä¼°')
    parser.add_argument('--model-path', type=str,
                       help='é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼ˆç”¨äºè¯„ä¼°ï¼‰')
    parser.add_argument('--visualize', action='store_true',
                       help='å¯è§†åŒ–é¢„æµ‹ç»“æœ')
    parser.add_argument('--export', action='store_true',
                       help='å¯¼å‡ºæ¨¡å‹')
    parser.add_argument('--export-formats', nargs='+', default=['onnx'],
                       help='å¯¼å‡ºæ ¼å¼åˆ—è¡¨')
    parser.add_argument('--predict', type=str,
                       help='é¢„æµ‹å•å¼ å›¾åƒçš„è¯»æ•°')
    
    args = parser.parse_args()
    
    # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
    if args.create_config:
        config_path = Path(args.config)
        config_path.parent.mkdir(parents=True, exist_ok=True)
        
        default_config = create_default_config()
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(default_config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"âœ… Default configuration created at: {config_path}")
        return
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not Path(args.config).exists():
        print(f"âŒ Configuration file not found: {args.config}")
        print("ğŸ’¡ Use --create-config to create a default configuration file")
        return
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨
    trainer = DigitsDetectionTrainer(args.config)
    
    try:
        if args.predict:
            # é¢„æµ‹å•å¼ å›¾åƒ
            if not args.model_path:
                print("âŒ Model path required for prediction")
                return
            
            reading = trainer.predict_reading(args.model_path, args.predict)
            print(f"ğŸ¯ Final reading: {reading}")
            
        elif args.eval_only:
            # åªè¿è¡Œè¯„ä¼°
            if not args.model_path:
                print("âŒ Model path required for evaluation")
                return
            
            metrics = trainer.evaluate(args.model_path)
            
            if args.visualize:
                trainer.visualize_predictions(args.model_path)
            
            if args.export:
                trainer.export_model(args.model_path, args.export_formats)
        
        else:
            # è¿è¡Œå®Œæ•´è®­ç»ƒæµç¨‹
            best_model_path = trainer.train()
            
            # è¯„ä¼°æ¨¡å‹
            metrics = trainer.evaluate(best_model_path)
            
            if args.visualize:
                trainer.visualize_predictions(best_model_path)
            
            if args.export:
                trainer.export_model(best_model_path, args.export_formats)
            
            print("ğŸ‰ Training pipeline completed successfully!")
            print(f"ğŸ“ Best model: {best_model_path}")
            print(f"ğŸ“Š Final mAP@0.5: {metrics['mAP50']:.4f}")
    
    except Exception as e:
        print(f"âŒ Error: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main() 